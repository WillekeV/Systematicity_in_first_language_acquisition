# Master_Thesis
All code for my master thesis on computational approaches to the study of systematicity and iconicity in language acquisition

The map childes_corpus_reader contains all code required to process the CHILDES corpus and extract from it 3 lists of lists for both child directed speech and child produced speech. The first list contains all tokens from the corpus, the second all corresponding lemmas, and the third all corresponding POS-tags. The corpus can be split according to the ages of the target children. The code was based on previously written code by Dr. Giovanni Cassani and Dr. Robert Grimm.

The map celex_reader contains all code required to process two of the obtained lists from the childes_corpus_reader code (the token list and the POS-tag list) to obtain form-embeddings for all tokens in the CHILDES corpus. To use it, you will need a copy of the CELEX database and a file containing a list of POS mappings, which can map the tags from the CHILDES corpus to the CELEX corpus. The code was almost entirely made by Dr. Giovanni Cassani, with some minor tweaks.

The map NDL_semantic_vectors contains all code required to make semantic vectors with Naive Discriminative Learning. You will need the list of tokens extracted from the CHILDES corpus with the childes_corpus_reader code to use as cues. You can then define your desired outcomes, or use this same token list as outcomes if you want to learn the direct mapping of tokens. The code was almost entirely made by Dr. Giovanni Cassani, with some minor tweaks.

The file helper_functions.py contains various functions that were used throughout the project for making semantic vectors, form vectors, obtaining wordcounts and map words to when they were first produced

The map FSC contains all code required to acquire FSC systematicity values for certain target words, providing a reference vocabulary. You need to run the fsc_main.py file and in the file itself you need to specify if you want to run the linux or windows version of the code. In order to make this code work, you need to supply the semantic space for both the reference (child-produced and child-directed) and target vocabulary (only child-directed), a file containing the word counts of all words in the target vocabulary and a file specifiying when the target words were first uttered by the child after hearing them for the first time. Optionally, you can also provide files containing concreteness, AoA, morphology and valence-measures and, if you want to work with phonetic transcription, you can include CELEX. The code returns a .json file containing for all target words the FSC-systematicity values, a measure of when the word is first produced and other relevant measures such as word-length, SND, etc.

The map FSC_baseline contains all code required to acquire 100 random baselines for FSC. It can be run in the same way as the FSC code and needs the the same semantic space and wordcount files. The code returns a .json file containing FSC-values for all target words 100 random baseline values.

The map FSC_baseline_strongvsweak contains all code required to acquire 10 strongvsweak baselines for FSC at the shuffle percentages of 10%, 50% and 90%. It can be run in the same way as the FSC code and needs the the same semantic space and wordcount files. The code returns a .json file containing FSC-values for all target words 10 strongvsweak baseline values at each percentage.

The map LDL contains all code required to acquire LDL systematicity values for certain target words, providing a reference vocabulary. You need to run the ldl_main.py file and in the file itself you need to specify if you want to run the linux or windows version of the code. In order to make this code work, you need to supply the semantic space for both the reference (child-produced and child-directed) and target vocabulary (only child-directed), the form spaces for both the reference and target vocabulary (only child directed), and a file containing the word counts of all words in the target vocabulary. The code returns a .json file containing LDL-values for all target words the LDL-systematicity values.

The map LDL_baseline contains all code required to acquire 100 random baselines for LDL. It can be run in the same way as the LDL code and needs the the same semantic space, form space and wordcount files. The code returns a .json file containing LDL-values for all target words 100 random baseline values.

The map LDL_baseline_strongvsweak contains all code required to acquire 10 strongvsweak baselines for LDL at the shuffle percentages of 10%, 50% and 90%. It can be run in the same way as the LDL code and needs the the same semantic space and wordcount files. The code returns a .json file containing LDL-values for all target words 10 strongvsweak baseline values at each percentage.

The file Neural_Networks.py contains all code to acquire cosine-losses, cosine-similarities and word-rankings for 3 different types of neural networks. The first neural network tries to predict vision vectors from semantic vectors, the second neural network tries to predict vision vectors from phonetics vectors and the third neural network tries to predict vision vectors from both semantic and vision vectors. In order to make this code work, you need to supply files containing semantic-vectors, vision-vectors and wordlists, which need to be alligned to each other. You can alter the code easily to provide the files you need, run random baselines and supply the output in the way you desire (e.g. in .csv or .txt format).
